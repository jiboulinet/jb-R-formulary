#Lire une base de donnée à l’écran
a<-read.table(file = "clipboard") 

#Exporter des données sous format excel :
library(xlsReadWrite)
write.table(myval,  "mytest.xls", sep = "\t")
#ou
write.table(mydata, "c:/mydata.txt", sep="\t")

#Pour ouvrir un fichier, enregistrer à partir d’excel en « txt  sep tab » puis vérifier que le fichier est bien en mode ANSI.
#Mettre la direction du fichier précédé de read.table() :
testhaplo<-read.table("C:/Documents and Settings/Khaled/Bureau/m0-m1-m3.txt",header=T,sep="")
#ou encore plus simple
test <- read.table(file.choose(), header=T)
 test<-as.data.frame(test)

#La fonction header=T (pour TRUE) indique que la première ligne du fichier correspond aux noms des colonnes et sep="" indique que le séparateur utilisé est un espace ou tabulation.
#Test de normalité
#Vérifier normalité de données : > shapiro.test(nomdufichier$variable)
#Ordonner une data.frame
mdrd1<-mdrd[ order(mdrd$id,mdrd$visite) ,]

#un autre plus compliqué
lss<-subset(mdata.16,evid==1|(time==0.5|time==1|time==2|time==3))
head(lss)
lss1<-lss[ order(lss$id,lss$time) ,]
head(lss1)

#Arrondir un nombre
expo1$visite<-round(expo1$visite,1)

#Chercher différence, égalité entre 2 base de données
###affiche les différences entre les 2 bases
setdiff(test$id,test1$id)
101,102,103…
##affiche les egalites entre 2 bases
intersect(test$id,test1$id)
106,110,113,208,…
###si id de test = id de dataset, alors variable new=1 sinon 0
test$new<-(test$id%in%Dataset$id)*1
test$delai<-ifelse(is.element(test$id,Dataset$id),Dataset$delai,NA
####ex
visit$creat<-(ifelse(is.element(visit$id,creat$id)&is.element(visit$Visit,creat$visit),creat$creat,NA))
> head(visit)
   id Visit Delais_j creat
1 101     1        0   563
2 101     2        1   367
3 101     3        0    NA
4 101     4        3    NA
5 101     5        5   178
6 101     6        7   133
>
Test10<-merge(long1, myf1,all=T)

#Puis remplacer les valeurs NA par 0
Test10$infection[is.na(test10$infection)] <- 0

#Merger plusieur bases en meme temps
Library(reshape)
my.list <- list(pat1, pat2, pat3, pat4)
t2<-merge_all(my.list)

#P values test t (student)
(1-(pt (1.96,171)))*2#1.96 est la valeur de t et n=171
[1] 0.05162092
#Exponentiel des coefficient, régression logistique odd ratio
exp(coef(glm2))
exp(confint(glm2,level = 0.95))

#Density plot
densityplot(~weight, test, groups = group, auto.key = TRUE, xlab = "Plant weight")

#Analyse gam et pourcentage de variabilité expliquée
Library(mgcv)
gam1<-gam(log(nfat1) ~ PPP3R1_3, data=ns)
> summary(gam1)

#Correction des p-values
srl_c0	visit	intercept	steroids	sexe	haplo	 delay	age
0,0001	0,5768	0,0001	0,0249	0,0388	0,0076	0,0188	0,0022
0,0059	0,6003	0,0001	NA	NA	NA	NA	NA
0,0058	0,3371	0,0001	NA	NA	NA	NA	NA
0,0203	0,0358	0,0001	NA	NA	NA	NA	NA
NA	0,0001	NA	NA	NA	NA	NA	NA
NA	0,3491	NA	NA	NA	NA	NA	NA
NA	0,0466	NA	NA	NA	NA	NA	NA
p<-Dataset$visit
p<-na.exclude(Dataset$age)

#tester bonferroni,hommel,holm,Hochberg
#Attention, p=nom du dataset? mettre p$p.value
p.adjust(p,7,method = "hochberg")#7 est le nombre de test multiple
#ou il mets p par défaut (mieux)
p.adjust.M <- p.adjust.methods
p.adj    <- sapply(p.adjust.M, function(meth) p.adjust(p$p.value, meth))##p.value=nom du dataset
noquote(apply(p.adj,2, format.pval, digits = 3))

#Test de Mann et Withney 
> wilcox.test(mpg ~ am, data=mtcars) 
 
        Wilcoxon rank sum test with continuity correction 
 
data:  mpg by am 
W = 42, p-value = 0.001871 
alternative hypothesis: true location shift is not equal to 0 

#Test Kruskall Wallis
kruskal.test(P30~g,data=test)
        Kruskal-Wallis rank sum test
data:  P30 by g 
Kruskal-Wallis chi-squared = 2.83, df = 3, p-value = 0.4192

#Summary par groupe
aggregates <- function(formula, data=NULL, FUNS){
   if(class(FUNS)=="list"){    f <- function(x) sapply(FUNS, function(fun) fun(x))   }else{f <- FUNS}   
       temp <- aggregate(formula, data, f)   
       out <- data.frame(temp[,-ncol(temp)], temp[,ncol(temp)])    
       colnames(out)[1] <- colnames(temp)[1] 
   return(out)  }

FUNS <- function(x) c(mean=round(mean(x),2), sd=round(sd(x), 2)) 

aggregates(AUC0.24~specialite*cyp3a5*periode, data=spe, FUNS=FUNS)


 aggregates(weight~group, data=PlantGrowth, FUNS=FUNS) 
  group mean   sd 
1  ctrl 5.03 0.58 
2  trt1 4.66 0.79 
3  trt2 5.53 0.44

#idem avec by
tapply(c10$delai,c10$cyp3a5,mean)

#Box and Whisker plot
bwplot(group ~ AUC, test, xlab = "groupe génotype")

#Coefficient de détermination (non reussi) : summary(geeglm1)$adj.r.squared ou summary(geeglm1)$r.squared. Attention, ne fonctionne pas si données manquantes.

Library(geepack)
glm1<-geeglm(LDL~visite+SRL+sexe,id=id,data=miss1,corstr="unstructured")

#La fonction head(nomdufichier) permet d’avoir un aperçu des 6 premières ligne de notre fichier.
Coefficient de correlation
plot(test$TRG,test$CHL)
> cor(test$TRG,test$CHL, use = "complete.obs")
> cor(test$TRG,test$CHL, use = "complete.obs",method="spearman")
cor.test(test$TRG,test$CHL, use = "complete.obs")

        Pearson's product-moment correlation

data:  test$TRG and test$CHL 
t = 5.1318, df = 473, p-value = 4.198e-07
alternative hypothesis: true correlation is not equal to 0 
95 percent confidence interval:
 0.1426281 0.3131522 
sample estimates:
      cor 
0.2296519

#Plot par groupe
plot(cov$H1~cov$cpu3_2, groups=cov$ex28,col=gray(seq(0, 1, 0.8)),xlab="difference in CPU between P3 and P1", ylab="k1 parameter")
abline(lm(cov$H1~cov$cpu3_2), col = "grey", lty="dotted", lwd=3)

#Supprimer une partie d’une chaine de caractères
x <- "ABC"
substring("ABC",2)#pour avoir BC

#Transformer une variable continue 1/0 en binaire: as.factor(variable)
response ~ as.factor(taille).

#Ou changer dans data frame 
spray <- as.integer(spray) ##permet de dire que c’est ordonnée ex 0,1,2,3,4
spray <- factor(spray, labels = LETTERS[1:6])

#Pour changer variable dans data.frame
test$EPO<-ifelse(test$EPO==0,"non","oui")

#Transformer des données d’une data frame en  données SNP :
Library(SNPassoc)
 > test<-setupSNP(miss1,20:27,sep="") puis summary(test) (attention, pour sélectionner des SNP non contiguês utiliser des « , » :  <-geno <- hla.demo[,c(17,18,21:24)]

#Rechercher association entre un phenotype et un SNP avec différents modèles génétiques :
> association (CHL~tor2,data=test1)

#Recoder un SNP dans un modèle génétique voulu :
#Petit programme écrit par Pierre Bady (CEMAGREF Aix)
recode <- function(x,...){
   UseMethod("recode")
}
recode.snp <-function(x,model="log-additive",type="value",...){
   require(SNPassoc)
   mod1 <- switch(model,"codominant"=SNPassoc:::codominant.default,
         "log-additive"= function(x) as.numeric(SNPassoc:::codominant.default(x)),
         "overdominant"=SNPassoc:::overdominant.default,
         "dominant"=SNPassoc:::dominant.default,
         "recessive"=SNPassoc:::recessive.default, stop("non convient model type!"))
   w <- switch(type, "value"= mod1(x),"model"= mod1, stop("non convient type!"))
   w
}
#Puis :
>test$ snp1 <- recode.snp(myDat[,6],model="log-additive") 
 glm(hta ~ snp1,family=binomial) 

Call:  glm(formula = hta ~ snp1, family = binomial) 

Coefficients: 
(Intercept)         snp1  
    -0.8099       0.2556  

Degrees of Freedom: 156 Total (i.e. Null);  155 Residual 
Null Deviance:       216.6 
Residual Deviance: 215.8    AIC: 219.8

#Supprimer une variable d’un data frame
test$G_rec <- NULL

#Supprimer une ligne d’un data frame
Dataset <- Dataset[!(rownames(Dataset) %in% c("5")),]

#Supprimer une ligne dupliquée
tacl3<-tacl2 [! duplicated (tacl2$id),]

#Pour avoir odd ratio à partir des coefficients betas
>Library(epicalc)
>  logistic.display(test)

#Résumé d’une data frame (statistiques descriptives) :
>codebook(test) ou > summ(test1)

#Faire un stepwise : attention aux données manquantes :
leuco_miss<-na.exclude(leucost)
> glm2<-glm(leuco~gen2+sexe+age+CMV+range+maj+rangempa,data=leuco_miss,family="binomial")
> modelstep<-step(glm2,direction="both")
direction = c("both", "backward", "forward"), 
trace = 1, keep = NULL, steps = 1000, k = 2, ...) 
trace=0 permet d’avoir uniquement le modele final
#Préférer la démarche forward
k=2 => AIC 
k=log(n) => BIC
#Exemple :
For AIC> step(model, data, direction, k=2, trace) # k=2 is by default
For BIC > step(model, data, direction, k=log(nrow(data)), trace)

#Comparaison de modèle emboités

fm2 <- lm(ia08 ~ ia09, data = myData) 
fm3 <- lm(ia08 ~ ia10, data = myData) 
anova(fm1, fm2, test = "F") 
anova(fm1, fm3, test = "F")
ou

#Test du LRT
lrtest (model1, model2, print=TRUE)    

#Changer de groupe de référence Cox ou regression logistique:
cathedral$style <- relevel(cathedral$style,ref="r")

#Régression cas/témoin
clogit1 <- clogit(case ~ smoking+alcohol+strata(matset),data=VC1to1)
#exactement égal à 
coxph(formula = Surv(rep(1, 52), case) ~ smoking + alcohol + strata(matset), method = "exact",data=VC1to1)
a<-coxph(formula = Surv(rep(1, 590), case) ~ haplo +age+ BMI+sexe+atcd+habitat+activite+viande+viandegrill+tabac+alcool+AINS+physique+strata(Strate), method = "exact",data=test1)
#Sélectionner une variable sans subset
minnfemale <- minnbreast[minnbreast$sex == “F” & !is.na(minnbreast$sex),]
#Cox model
> tcox<-coxph(Surv(delay,loss)~haplotype+ager+aged+sexer+sexed+bpar+isch,data=test)
> summary(tcox)
Call:
coxph(formula = Surv(delay, loss) ~ haplotype + ager + aged + 
    sexer + sexed + bpar + isch, data = test)

  n=253 (6 observations deleted due to missingness)

                      coef  exp(coef)   se(coef)      z Pr(>|z|)   
haplotypehetero  1.2115697  3.3587527  0.6674199  1.815  0.06948 . 
haplotypehomoz   2.1562696  8.6388513  0.7281344  2.961  0.00306 **
ager            -0.0038988  0.9961088  0.0188662 -0.207  0.83628   
aged             0.0252560  1.0255776  0.0207097  1.220  0.22265   
sexerM           0.0058587  1.0058759  0.4881277  0.012  0.99042   
sexedM           0.1816907  1.1992432  0.5290482  0.343  0.73128   
bpar             0.9517130  2.5901429  0.4931087  1.930  0.05360 . 
isch            -0.0001614  0.9998386  0.0006262 -0.258  0.79664   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

                exp(coef) exp(-coef) lower .95 upper .95
haplotypehetero    3.3588     0.2977    0.9080    12.425
haplotypehomoz     8.6389     0.1158    2.0733    35.995
ager               0.9961     1.0039    0.9599     1.034
aged               1.0256     0.9751    0.9848     1.068
sexerM             1.0059     0.9942    0.3864     2.618
sexedM             1.1992     0.8339    0.4252     3.382
bpar               2.5901     0.3861    0.9853     6.809
isch               0.9998     1.0002    0.9986     1.001

Rsquare= 0.066   (max possible= 0.513 )
Likelihood ratio test= 17.31  on 8 df,   p=0.02700
Wald test            = 16.24  on 8 df,   p=0.03902
Score (logrank) test = 19.75  on 8 df,   p=0.01133
> test_na<-na.exclude(test)
> tcox<-coxph(Surv(delay,loss)~haplotype+ager+aged+sexer+sexed+bpar+isch,data=test_na)
> stepw<-step(tcox,direction="both")

#Tester de nombreux SNP sur un phénotype
> ansAll<-WGassociation(protein~1,data=datSNP,model="all")
> summary(ansAll)
 SNPs (n) Genot error (%) Monomorphic (%) Significant* (n) (%)
       35               0            34.3                0   0

 *Number of statistically significant associations at level 1e-06
> ansAll
          comments    codominant dominant recessive overdominant log-additive
snp10001  -           0.00492    0.00456  0.01491   0.12102      0.00114     
snp10002  -           0.78525    0.93292  0.48600   0.87267      0.76807     
snp10003  Monomorphic -          -        -         -            -           
snp10004  Monomorphic -          -        -         -            -           
snp10005  -           0.63220    0.43763  0.50030   0.55340      0.37129     
snp10006  Monomorphic -          -        -         -            -           
snp10007  Monomorphic -          -        -         -            -           
snp10008  -           0.20293    0.29843  0.08453   0.83628      0.13289     
snp10009  -           0.74695    0.87183  0.47708   0.68095      0.93605     
snp100010 Monomorphic -          -        -         -            -           
snp100011 -           0.30259    0.12717  0.27118   0.28248      0.12583     
snp100012 -           0.70516    0.58280  0.47821   0.72292      0.48889     
snp100013 -           0.14592    0.09659  0.10819   0.38274      0.05278     
snp100014 -           0.03531    0.01398  0.11743   0.26964      0.01143     
-        -         -            -           

#Correction de Bonferroni
> Bonferroni.sig(ansAll,model="codominant",alpha=0.05,include.all.SNPs=FALSE)
number of tests:  22 
alpha: 0.05 
corrected alpha: 0.002272727 
   No significant SNPs after Bonferroni correction
table avec p de HWE
> ans<-setupSNP(SNPs,6:40,sep="")
> res<-tableHWE(ans)
> print(res)
          HWE (p value) flag
snp10001  0.2816            
snp10002  0.0049        <-  
snp10003  -                 


#Valeur de LD
LD(graft1$c1236t,graft1$g2677t)
Pairwise LD
-----------
                   D        D'      Corr (=r²)
Estimates: 0.2289291 0.9390237 0.9353278

              X^2 P-value   N
LD Test: 362.1829       0 207
Tester plusieurs LD
Avec package SNPassoc
Plot(ans)
a<-LD(ans)
LDtable(a)
 

Arguments :LDtable(a, colorcut = c(0, 0.01, 0.025, 0.05, 0.1, 1), colors = heat.colors(length(textcol = "black", digits = 3, show.all = FALSE, which = c("D","D'", "r", "X^2", "P-value", "n"))))
Faire et tester les haplotypes  
    > tag.SNP<-c("tor1","tor2","tor3")
> geno<-make.geno(test1,tag.SNP)
> mod<-haplo.glm(LDL~geno+cortico,data=test1,family="gaussian",locus.label=tag.SNP,control=haplo.glm.control(haplo.freq.min=0.05))
> mod

  Call: 
haplo.glm(formula = LDL ~ geno + cortico, 
    family = "gaussian", data = test1, locus.label = tag.SNP, 
    control = haplo.glm.control(haplo.freq.min = 0.05)
Coefficients:
               coef    se t.stat     pval
(Intercept)  2.5327 0.286  8.866 8.44e-15
geno.2      -0.2946 0.268 -1.099 2.74e-01
geno.5      -0.0822 0.132 -0.621 5.36e-01
geno.6       0.3486 0.232  1.500 1.36e-01
geno.rare   -0.2382 0.395 -0.604 5.47e-01
corticooui   0.3201 0.243  1.315 1.91e-01

Haplotypes:
           tor1 tor2 tor3 hap.freq
geno.2        A    A    G   0.0911
geno.5        C    A    G   0.3334
geno.6        C    G    A   0.1180
geno.rare     *    *    *   0.0279
haplo.base    A    G    A   0.4295
OR et CI95% pour haplo.glm
> intervals(mod)
               freq   or   95%   C.I.   P-val 
         CTG 0.4427   1.00 Reference haplotype 
         GCA 0.2318   0.95 (   0.54 -   1.69 )  0.8705 
         GTG 0.2987   1.01 (   0.52 -   1.97 )  0.9773 
   geno.rare 0.0268   0.22 (   0.05 -   0.99 )  0.0490 

#Description et fréquence des haplotypes
> freqhaplom<-haplo.em(geno=geno)
> print(freqhaplom) )#attention, il code les snp par loc1, loc2… etc et surtout 1 ou 2 : 1 correspond à la lettre la + basse dans l’alphabet et non à l’allèle sauvage !!! (ex : (1) A>G, A=1, G=2 ; (2) G>A, A=1, G=2).
=============================================================================== 
                                  Haplotypes                                    
=============================================================================== 
  loc-1 loc-2 loc-3 hap.freq
1     1     1     2  0.00000
2     1     2     2  0.44268
3     2     1     1  0.23209
4     2     1     2  0.01313
5     2     2     1  0.01309
6     2     2     2  0.29901
=============================================================================== 
                                    Details                                     
=============================================================================== 
lnlike =  -293.0304 
lr stat for no LD =  252.0424 , df =  1 , p-val =  0
Haplotype par patients
> summary(freqhaplom,nlines=10)
           Subjects: Haplotype Codes and Posterior Probabilities              
=============================================================================== 
    subj.id hap1code hap2code posterior
1         1        2        2   1.00000
2         2        2        6   1.00000
3         3        2        2   1.00000
4         4        5        1   0.00000
5         4        2        3   1.00000
6         5        6        2   1.00000
7         6        2        2   1.00000
8         7        6        2   1.00000
9         8        6        2   1.00000
10        9        5        1   0.00000
=============================================================================== 
                    Number of haplotype pairs: max vs used                      
=============================================================================== 
   
x     1   2   4
  1 106   0   0
  2   1  31   0
  4   0  18   1
>


#Choix du modèle génétique pour l’analyse haplotypique (par défaut, additive)
>  mod<-haplo.glm(casco~geno,data=datSNP,family="binomial",locus.label=tag.SNPs, control=haplo.glm.control(haplo.freq.min=0.05,haplo.effect="additive"))
> mod

  Call: 
haplo.glm(formula = casco ~ geno, family = "binomial", 
    data = datSNP, locus.label = tag.SNPs, 
    control = haplo.glm.control(haplo.freq.min = 0.05, 
        haplo.effect = "additive")

Coefficients:
                coef    se  t.stat    pval
(Intercept)  0.95932 0.337  2.8453 0.00505
geno.3      -0.04761 0.292 -0.1631 0.87069
geno.6       0.00966 0.340  0.0284 0.97737
geno.rare   -1.50456 0.764 -1.9685 0.05081

Haplotypes:
           snp100019 snp10001 snp100029 hap.freq
geno.3             G        C         A   0.2318
geno.6             G        T         G   0.2987
geno.rare          *        *         *   0.0268
haplo.base         C        T         G   0.4427


#Changer haplotype de référence
>  mod<-haplo.glm(casco~geno,data=datSNP,family="binomial",locus.label=tag.SNPs,control=haplo.glm.control(haplo.freq.min=0.05,haplo.base=4)) ##chercher haplotype dans la liste d’haplotype initiale
> mod

  Call: 
haplo.glm(formula = casco ~ geno, family = "binomial", 
    data = datSNP, locus.label = tag.SNPs, 
    control = haplo.glm.control(haplo.freq.min = 0.05, 
        haplo.base = 4))

Coefficients:
             coef   se t.stat   pval
(Intercept) -3.27 2.32 -1.412 0.1601
geno.2       2.12 1.19  1.791 0.0753
geno.3       2.05 1.18  1.741 0.0837
geno.6       2.13 1.19  1.786 0.0761
geno.rare    1.14 1.54  0.745 0.4572

Haplotypes:
           snp100019 snp10001 snp100029 hap.freq
geno.2             C        T         G   0.4427
geno.3             G        C         A   0.2317
geno.6             G        T         G   0.2988
geno.rare          *        *         *   0.0133
haplo.base         G        C         G   0.0135



#Test des haplotypes en design cas-temoins
haplo.cc(case, geno, locus.label=NA, ci.prob=0.95, miss.val=c(0,NA), weights=NULL, eps.svd=1e-5, simulate=FALSE, sim.control=score.sim.control(), control=haplo.glm.control())
----------------------------------------------------------------------------------------------- 
                                 Counts for Cases and Controls                                   
------------------------------------------------------------------------------------------------ 
control    case 
    141     141 


------------------------------------------------------------------------------------------------ 
            Haplotype Scores, p-values, Hap-Frequencies (hf), and Odds Ratios (95%               
                                              CI)                                                
------------------------------------------------------------------------------------------------ 
  loc-1 loc-2 loc-3 Hap-Score     p-val  pool.hf control.hf   case.hf glm.eff OR.lower      OR
8     2     2     2  -2.91552 0.0035509 0.341887  0.4023200 0.2814589     Eff 0.385951 0.56104
3     1     2     1  -1.70557 0.0880876 0.011024  0.0190258 0.0033350     Eff 0.011050 0.15681
4     1     2     2  -1.52295 0.1277723 0.014497  0.0212901 0.0075923     Eff 0.055115 0.30100
6     2     1     2  -0.73526 0.4621840 0.010633  0.0153129 0.0061534     Eff 0.021958 0.24656
2     1     1     2   0.20246 0.8395597 0.083338  0.0788075 0.0877741     Eff 0.442531 0.84479
5     2     1     1   0.68338 0.4943638 0.023754  0.0179108 0.0295966     Eff 0.339388 1.10829
7     2     2     1   1.07133 0.2840203 0.013798  0.0077187 0.0196706     Eff 0.430318 2.54683
1     1     1     1   3.01415 0.0025770 0.501070  0.4376142 0.5644192    Base       NA 1.00000
  OR.upper
8  0.81556
3  2.22527
4  1.64379
6  2.76860
2  1.61270
5  3.61916
7 15.07337
1       NA



#Paramètres graphiques : nuance de gris
palette(gray(0:5 / 5))
 hist(a,col=1:4, yaxt="n")



#Calcul du nombre de sujet et puissance gencolon haplotype mdr1

haplo <- rbind(c(  2, 2, 2),c( 1, 2, 1),c( 1, 2,2),c(  2, 1, 2),c( 1, 1, 2),c(  2, 1, 1),c( 2, 2, 1),c( 1, 1, 1))
dimnames(haplo)[[2]] <- paste("loc", 1:ncol(haplo), sep=".")
haplo <- data.frame(haplo)
haplo.freq <- c(0.341887, 0.011024, 0.014497, 0.010633, 0.083338, 0.023754, 0.013798, 0.501070)
# define index for risk haplotypes (having alleles 1-1 at loci 2 and 3)
haplo.risk <- (1:nrow(haplo))[haplo$loc.1==1&haplo$loc.2==1 & haplo$loc.3==1]
# define index for baseline haplotype
base.index <- 1
# specify OR for risk haplotypes
or <- 2.0
# determine beta regression coefficients for risk haplotypes
haplo.beta <- numeric(length(haplo.freq))
haplo.beta[haplo.risk] <- log(or)
# Note that non-risk haplotypes have beta=0, as does the intercept
# (haplotype with base.index value).
# Compute total sample size for given power
haplo.power.cc(haplo, haplo.freq, base.index, haplo.beta, case.frac=.5, prevalence=.1, alpha=.05, power=.8)
# Compute power for given sample size
haplo.power.cc(haplo, haplo.freq, base.index, haplo.beta, case.frac=.5, prevalence=.1, alpha=.05, sample.size=600)



#Modifier selon critère une data frame
•	Sélectionner que certaine colonnes : >test1<-test[,c('visite','age','sexe')]
•	Sélectionner les lignes de 1 à 30>test1<-test[1:30,]
•	Sélectionner que les visites 2 >visite2<-test[test$visit==2,]
•	Sélectionner que les patients sous cortico >corti2<-test[test$cortico== »oui »,]

Pour avoir une information détaillée sur un package (site internet en relation) : 
> RSiteSearch("lme4")


Bootstraping
test
   AR p17 p24
1   1   1   1
2   1   1   1
3   1   1   1
4   1   1   1
5   1   1   1
6   1   1   1
7   1   1   0
8   1   1   1
9   1   1   0
10  1   1   0
11  1   1   0
12  1   1   1
13  1   1   1
14  1   0   1
15  1   0   1
16  1   1   1
17  1   1   0
18  1   1   1
19  0   1   0
20  0   1   0
21  0   1   0
22  0   0   0
theta <- function(x, tab) coef(glm(AR~p17+p24, family=binomial(), data=tab[x,])) 
results <- bootstrap(1:nrow(test), 50, theta, test)
results1 <- bootstrap(1:nrow(test), 50, theta, test)
Vérifier la reproductibilité:
set.seed(0) 
res1 <- bootstrap(1:nrow(test), 50, theta, test) 
set.seed(0) 
res2 <- bootstrap(1:nrow(test), 50, theta, test) 
all.equal(res1,res2) 
[1] TRUE

#Avec package boot
Library(boot)
bs <- function(formula, data, indices) {
   d <- data[indices,] # allows boot to select sample 
  fit <- glm(formula, data=d,family="binomial")
  return(coef(fit)) }
results <- boot(data=mtcars, statistic=bs,  R=100, formula=am~wt+disp)

#Pour modèle de Cox
bs <- function(formula, data, indices) {
    d <- data[indices,] # allows boot to select sample 
   fit <- coxph(formula, data=d)
 return(coef(fit)) }
 results <- boot(data=test4, statistic=bs,  R=100, formula=Surv(delay,dialyse)~age+sex)
head(results)

results <- boot(data=cox1, statistic=bs,  R=20, formula=Surv(delai_event,event)~haplotype)
a<-as.data.frame(results$t)
colnames(a)<-c("hetero","mutant")
 head(a)
#quantile
quantile(a$hetero,  probs = c(0.25, 0.5,0.75))
#µ IC95%
b<-mean(a$hypo)
 c<-sd(a$hypo)
#HR
exp(b)
 #IC95% bas
exp( b-1.96*c)
 #IC95% haut
exp( b+1.96*c)


#Bootstraper une base de données
test2<-replicate (10,echantillon<- sample(1:nrow(test1),nrow(test1), replace = TRUE))
res<-test1[test2,]

#Exporter des résultats
>  write.csv2(results, file="boot.csv", dec=".",sep="")
print.infile(test1, file="test-cov1.txt")
#Courbes de ROC
glm1<-glm(CN1~p17+p35,binomial,test)
> glm2<-glm(CN1~p17,binomial,test)
> glm3<-glm(CN1~p35,binomial,test)
> lroc1 <- lroc(glm1)
> lroc2 <- lroc(glm2, add=TRUE, line.col="brown", lty=2)
> lroc3 <- lroc(glm3, add=TRUE, line.col="black", lty=2)
> legend("bottomright",legend=c(lroc1$model.description, lroc2$model.description,lroc3$model.description),
 lty=1:2, col=c("red","brown"), bg="white")
> title(main="Comparison of 3 logistic regression models")
>
La fonction lty change les pointillés (lty1,lty2…).

####Superbe  courbes
Ou library(Epi)
ROC( form = CNi ~p17+p35, plot="ROC" )#cf library Epi pour arguments)

Variables dépendantes du temps dans Cox
1-Copier la fonction « fold » ci-dessous
fold <- function(data, time, event, cov, 
    cov.names=paste('covariate', '.', 1:ncovs, sep=""), 
     suffix='.time', cov.times=0:ncov, common.times=TRUE, lag=0){
  vlag <- function(x, lag) c(rep(NA, lag), x[1:(length(x)-lag)])
     xlag <- function(x, lag) apply(as.matrix(x), 2, vlag, lag=lag)
     all.cov <- unlist(cov)
     if (!is.list(cov)) cov <- list(cov)
     ncovs <- length(cov)
     nrow <- nrow(data)
     ncol <- ncol(data)
     ncov <- length(cov[[1]])
     nobs <- nrow*ncov
     if (length(unique(c(sapply(cov, length), length(cov.times)-1))) > 1)
         stop(paste(
             "all elements of cov must be of the same length and \n",
             "cov.times must have one more entry than each element of cov."))
     var.names <- names(data)
     subjects <- rownames(data)
     omit.cols <- if (!common.times) c(all.cov, cov.times) else all.cov
     keep.cols <- (1:ncol)[-omit.cols]
     nkeep <- length(keep.cols)
     if (is.numeric(event)) event <- var.names[event]
     times <- if (common.times) matrix(cov.times, nrow, ncov+1, byrow=T)
         else data[, cov.times]
     new.data <- matrix(Inf, nobs, 3 + ncovs + nkeep)
     rownames <- rep("", nobs)
     colnames(new.data) <- c('start', 'stop', paste(event, suffix, sep=""), 
         var.names[-omit.cols], cov.names)
     end.row <- 0
     for (i in 1:nrow){
         start.row <- end.row + 1
         end.row <- end.row + ncov
         start <- times[i, 1:ncov]
         stop <- times[i, 2:(ncov+1)]
         event.time <- ifelse (stop == data[i, time] & data[i, event] == 1, 1, 0)
         keep <- matrix(unlist(data[i, -omit.cols]), ncov, nkeep, byrow=T)
         select <- apply(matrix(!is.na(data[i, all.cov]), ncol=ncovs), 1, all)
         rows <- start.row:end.row
         cov.mat <- xlag(matrix(unlist(data[i, all.cov]), nrow=length(rows)), lag)
         new.data[rows[select], ] <- 
             cbind(start, stop, event.time, keep, cov.mat)[select,]
         rownames[rows] <- paste(subjects[i], '.', seq(along=rows), sep="")
         }
     row.names(new.data) <- rownames
     as.data.frame(new.data[new.data[, 1] != Inf & 
         apply(as.matrix(!is.na(new.data[, cov.names])), 1, all), ])
     }

Arguments of fold:
##  data: A data frame or numeric matrix (with column names) to be `unfolded.' 
##      For reasons of efficiency, if there are factors in data these will be 
##      converted to numeric variables in the output data frame.
##  time: The quoted name of the event/censoring-time variable in data.
##  event: The quoted name of the event/censoring-indicator variable in data.
##  cov: A vector giving the column numbers of the time-dependent covariate 
##      in data, or a list of vectors if there is more than one time-varying 
##      covariates.
##  cov.names: A character string or character vector giving the name or names 
##      to be assigned to the time-dependent covariate(s) in the output data set.
##  suffix: The suffix to be attached to the name of the time-to-event variable 
##      in the output data setl defaults to '.time'.
##  cov.times: The observation times for the covariate values, including the start 
##      time. This argument can take several forms: 
##      *   The default is integers from 0 to the number of covariate values (i.e., 
##              one more than the length of each vector in cov).
##      *   An arbitrary numerical vector with one more entry than the length of each 
##      *       vector in cov.
##      *   The columns in the input data set that give the observations times for each
##              individual. There should be one more column than the length of each 
##              vector in cov.
##      *   common.times: A logical value indicating whether the times of observation 
##              are the name for all individuals; defaults to TRUE.
##      *   lag: Number of observation periods to lag each value of the time-varying 
##              covariate(s); defaults to 0.

Exemple : 
head(test)
  id   m6  m12  m24  m36 event delay age sexe 
1  1 13.2 13.1 12.5 11.9      0    92  53    F   
2  2 12.4 13.3 11.7   NA      1     1  36    M   
3  3 14.7 14.2   NA 12.8      0    92  55    M   
4  5 12.7   NA 10.9 11.4      0    56  18    M   
5  6 14.5 15.6 14.3 13.7      0    92  37    M   
6  7 11.5 10.9 12.0 12.1      0    92  56    M   

test.2 <- fold(test, time="delay",event="cutane", cov=2:5, cov.names="anemia")
> head(test.2)
    start stop cutane.time id cutane delay age sexe hb
1.1     0    1           0  1      0    92  53    1   13.2
1.2     1    2           0  1      0    92  53    1   13.1
1.3     2    3           0  1      0    92  53    1     12.5
1.4     3    4           0  1      0    92  53    1   11.9
2.1     0    1           1  2      1     1  36    2   12.4
2.2     1    2           0  2      1     1  36    13.3
> jb_cox.2 <- coxph(Surv(start, stop, cutane.time) ~age + sexe +anemia,data=test.2)
> summary(jb_cox.2)
Call:
coxph(formula = Surv(start, stop, cutane.time) ~ age + sexe + 
    anemia, data = test.2)

  n=394 (4 observations deleted due to missingness)

            coef exp(coef)  se(coef)      z Pr(>|z|)
age    -0.003359  0.996647  0.013820 -0.243    0.808
sexe    0.901402  2.463053  0.553949  1.627    0.104
anemia -0.049021  0.952161  0.131416 -0.373    0.709

       exp(coef) exp(-coef) lower .95 upper .95
age       0.9966      1.003    0.9700     1.024
sexe      2.4631      0.406    0.8317     7.295
anemia    0.9522      1.050    0.7360     1.232

Rsquare= 0.008   (max possible= 0.439 )
Likelihood ratio test= 3.19  on 3 df,   p=0.3636
Wald test            = 2.68  on 3 df,   p=0.4433
Score (logrank) test = 2.84  on 3 df,   p=0.4169

Attention, le seul problème est qu’il faut faire une colonne par unité de temps (ex suivi de 0 à 92 mois, il faut 92 colonnes).
Fonction reshape (transformer une data frame en données longitudinales) :
head(test)
  id vgm_m0 leuco_m0 vgm_m1 leuco_m1 vgm_m3 leuco_m3 vgm_m6 leuco_m6
1  1   91.0     6670   88.6     6610   87.0     7560   83.6     8550
2  2   90.9     5340     NA     5700     NA       NA     NA       NA
3  3   93.2    11740     NA       NA   87.0     5950   84.0     8700
4  5     NA       NA   85.0     8200   81.0     8400   78.0    12300
5  6   86.0    11580   86.0     8300   84.0     8200   83.0     7100
6  7   87.6     6000   87.6     5690   87.6     5690   81.0     5490
test1<-reshape(test,idvar="id",varying=list(c("vgm_m0","vgm_m1","vgm_m3","vgm_m6")),v.names="vgm",times=c("0","1","3","6"),direction="long")
mtx1<-reshape(mtx,idvar="id",varying=list(c("c0","c1","c2","c3","c4",”c5”,”c6”),c(delai_0,delai_1,delai_2,delai_3,delai_4,delai_5,delai_6)),v.names="vgm",times=c("0","1",”2”,"3",”4”,”5”,"6"),direction="long")

#ou plus compliqué quand plusieurs variables
reshape(test,varying=list(c("D_MMF_S2","D_MMF_S6","D_MMF_S12","D_MMF_S26","D_MMF_S52"),c("AUC_MMF_S2","AUC_MMF_S6","AUC_MMF_S12","AUC_MMF_S26","AUC_MMF_S52"),c("D_csa_S2","D_csa_S6","D_csa_S12","D_csa_S26","D_csa_S52"),c("CsA_C0_S2","CsA_C0_S6","CsA_C0_S12","CsA_C0_S26","CsA_C0_S52"),c("CsA_C2_S2","CsA_C2_S6","CsA_C2_S12","CsA_C2_S26","CsA_C2_S52")),v.names=c("D_MMF","AUC_MMF","D_csa","CsA_C0","CsA_C2"),times=c("2","6","12","26","52"),direction="long")
##reordonner/ordonné/trier dataset
> test2 <- test1[order(test1$id), ]
> head(test2)
    id time  vgm leuco
1.0  1    0 91.0  6670
1.1  1    1 88.6  6610
1.3  1    3 87.0  7560
1.6  1    6 83.6  8550
2.0  2    0 90.9  5340
2.1  2    1   NA  5700



#Dans l’autre sens :
testwide<-reshape(test,v.names=c("cortico", "SRL", “chl"),idvar="id",timevar="visite",direction="wide")
 head(testwide) 

#Exemple de modèle de Cox avec variables dépendantes du temps

1) Utiliser la fonction expand.breakpoints



expand.breakpoints <-
function(dataset, index = "patnum", status = "status", tevent = "time", 
       Zvar = F, breakpoints = NULL)
{
# Expand <dataset> so that each individual has a row for each 
# unique failure time that is <= his/her/its own failure time.
#
# Original version written by Kathy Russell, for
# Kenneth Hess, Department of Biomathematics, 
# University of Texas M. D. Anderson Cancer Centre.
#
# Substantially modified by JHM, Nov 23, 1998.
#
# ERROR checking
        onceonly <- paste("must be a character string matching exactly", 
                "one name in the first parameter, dataset")     
        # Require dataset to be of type data.frame
        if((missing(dataset) || !is.data.frame(dataset)))
                stop("\n   Parameter, dataset, must be a data frame")
        varset <- names(dataset)
        covset <- varset
        lvset <- 1:length(varset)       # Require dataset to have unique names
        if(any(duplicated(varset))) {
                stop(paste("\n Parameter, dataset, must have uniquely defined", 
                        "column  names"))
        }
# Require index to match exactly 1 dataset name
        if(length((indexloc <- lvset[varset == index])) != 1)
                stop(paste("\n   Parameter, index,", onceonly))
        covset <- covset[covset != index]       
        # Require status to match exactly 1 dataset name
        if(length((statusloc <- lvset[varset == status])) != 1)
                stop(paste("\n   Parameter, status,", onceonly))
        covset <- covset[covset != status]      
        # Require tevent to match exactly 1 dataset name
        if(length((teventloc <- lvset[varset == tevent])) != 1)
                stop(paste("\n   Parameter, tevent,", onceonly))
        covset <- covset[covset != tevent]      # -----------------------------
# Form vector of breakpoints, if necessary
        if(is.null(breakpoints)) {
                times <- dataset[, tevent]
                breakpoints <- sort(unique(times[dataset[, status] == 1]))
        }
# Require breakpoints to be a vector of length >= 1
        if((is.null(breakpoints)) || (!(is.numeric(
             breakpoints))) || (!(is.vector(
                breakpoints))) || (length(breakpoints) < 1)) stop(paste(
                        "\n  Parameter, breakpoints, must be a numeric vector", 
                        "with at least 1 element"))     #*****************
#Begin
#*****************
        n <- nrow(dataset)
        temp.stop <- c(breakpoints, 0)  # The 0 is a place-filler
        if(breakpoints[1] > 0)
                temp.start <- c(0, breakpoints)
        else temp.start <- c(-1, breakpoints)
        n.break <- length(breakpoints) + 1
        t.event <- dataset[, tevent]    # ---------------------------
## Begin calculate n.epochs
        n.epochs <- sapply(1:n, function(m, breaks, times)
        sum(breaks < times[m]) + 1, breaks = breakpoints, times = t.event)      
        # End n.epochs
        id <- rep(1:n, n.epochs)        # Index into supplied dataset
        last.epoch <- cumsum(n.epochs)
        epoch <- unlist(sapply(n.epochs, function(x)
        1:x))   # Index into vectors of interval start & stop points
        if(Zvar) {
                Zmat <- diag(rep(1, n.break))[epoch,  ]
                Z.name <- paste("Z", seq(1, n.break), sep = "")
        }
        Tstop <- temp.stop[epoch]
        Tstop[last.epoch] <- dataset[, tevent]
        status2 <- rep(0, length(epoch))
        status2[last.epoch] <- dataset[, status]
        new.dataset <- data.frame(dataset[id, index, drop = F], 
temp.start[epoch], 
                Tstop, status2, epoch, dataset[id, covset, drop = F])
        if(Zvar)
                new.dataset <- data.frame(new.dataset, Zmat)
        nam <- c(index, "Tstart", "Tstop", status, "epoch", covset)
        if(Zvar)
                nam <- c(nam, Z.name)
        dimnames(new.dataset) <- list(1:length(epoch), nam)
        return(new.dataset)
}

#Puis faire
Attach(test)
breakpoints <- sort(unique(time))
#breakpoints permet de voir le nombre de classe’ qui sera utilize pour le fichier avec 
#covariable dépendante du temps
> test.exp <- expand.breakpoints(test,breakpoints,tevent="delay",status="dialyse", index="NATT", Zvar=FALSE)

#Ordonner une data frame par 2 facteurs
ciclo1 <- ciclo[order(ciclo[,1],ciclo[,2],decreasing=F),]

#Si trop long, recréer une data frame avec que les fichiers que l’on veut
test1<-data.frame(test.exp[,1:12])
> head(test1)
#ou
> test3<-data.frame(test2$NATT,test2$time,test2$Prot)
> test3 <- test3[order(test3$test2.NATT), ]

> head(test3)

#Puis sauver en txt :
print.infile <- function (x, file=NULL,...)    { capture.output(print(x,...), file=file)  }
 print.infile(test.exp, file="test-exp.txt")


2) Créer dans notre fichier avec variable dependante du temps le nombre de colonne correspondante à breakpoints et remplacer les vides par NA
Charger le fichier dans R et utiliser la fonction reshape

test1<-reshape(test,idvar="id",varying=list(c("vgm_m0","vgm_m1","vgm_m3","vgm_m6")),v.names="vgm",times=c("0","1","3","6"),direction="long")
ou plus compliqué
> test1<-reshape(test,idvar="NATT",varying=list(c("PAP0","PAP1","PAP2","PAP3","PAP4","PA_puls","PAP6","PAP7","PAP8","PAP9","PAP10","PAP11","PAP12","PAP13","PAP14","PAP15","PAP16","PAP17","PAP18","PAP19","PAP20","PAP21","PAP22","PAP23","PAP24","PAP25")),v.names="PAP",times=c("0","1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25"),direction="long")
> test2 <- test1[order(test1$id), ]
Si trop long, recréer une data frame avec que les fichiers que l’on veut
> test3<-data.frame(test2$NATT,test2$time,test2$Prot)
> test3 <- test3[order(test3$test2.NATT), ]
> head(test3)

> print.infile(test1, file="test-cov1.txt")

3)
Créer deux tables dans access avec le fichier 1.txt et 2.txt et les coupler par id/id et time/Tstop dans une requête
Copier le fichier ainsi créer dans un txt et l’importer dans R puis faire tourner le modèle de Cox :
> jb_cox <- coxph(Surv(Tstart, Tstop, death) ~age + sexe +anemia,data=test)
> summary(jb_cox)
>lrtest (cox1, cox2, print=TRUE)  


Puis
> test3<-merge(test1, test2)
Regroupe les 2 tables par attributs communs (ici NATT et Tstop)

#Modèle Inférence (cf livre de Burnham et Anderson)
library(MuMIn)
lm1<-lmer(hb~1+visite+I(visite^2)+(visite|id)+haplo_mtor_hb+SRL,data=test,REML=F)
options(na.action = "na.fail")
 dredge(lm1)

 
dd<-dredge(lm1)
options(na.action = "na.fail")
top.models.2 <- get.models(dd, subset = delta < 2, method = "ML")
 top.models.2
Modèle avec au moins 2 termes
dd<-dredge(lm1, m.max = 2)
Modèle avec visite forcée
dredge(lm1, fixed = "visite")
Modèle averaging (fait la moyenne des coefficients entre les meilleurs modèles)
model.avg(get.models(dd, subset = delta < 4)) # get averaged coefficients
 
Classer les modèles selon le BIC
BIC <- function(x) AIC(x, k=log(length(residuals(x))))
> mav <- model.avg(top.models, rank=BIC)
 

#Exemple de modèle joint
Attention, il faut qu’il n y ait aucune valeur manquante dans la variable expliquée ou les covariables pour fitter le lme
lmeFit <- lme(sqrt(CD4) ~ obstime * drug, random = ~ obstime | patient, data = aids)
coxFit <- coxph(Surv(Time, death) ~ drug, data = aids.id, x = TRUE)
fitJOINT <- jointModel(fitLME, fitCOX,timeVar = "obstime", method = "spline-PH-GH")
summary(fitJOINT)

#Graphe
fitJOINT <- jointModel(fitLME, fitSURV, timeVar = "year")
plot(fitJOINT, 3, add.KM = TRUE, col = "red", lwd = 2)
par(mfrow = c(2, 2))
plot(fitJOINT)


#Faire une courbe de ROC et déterminer le seuil

library(pROC)
roc(aSAH$outcome, aSAH$s100b, plot=TRUE,print.thres=T)

Call:
roc.default(response = aSAH$outcome, predictor = aSAH$s100b,     plot = TRUE, print.thres = T)

Data: aSAH$s100b in 72 controls (aSAH$outcome Good) < 41 cases (aSAH$outcome Poor).
Area under the curve: 0.7314

Meilleur seuil :
coords(rocobj, "b", ret="t")




#Modèle de cox avec variables dépendantes du temps : method Survsplit

head(test)
  id haplotype cyp3A5 rejet_aigu event delai_event csa1 csa2 csa3 csa4 csa0
1  3       het    NEs          1     1        10.2  153  213  119  236  NaN
2  4       het    NEs          1     1         5.8  174  288  173  158  NaN
3  5       hom     Es          0     1         3.9  226  177  147  254  NaN
4  7       het     Es          1     1         3.3  255  167  223  245  NaN
5  8       het    NEs          1     1         6.8  231  282  237  210  NaN
6  9       het     Es          1     1         1.2  234  164  238  155  NaN

test1<-survSplit(test,cut=c(1,2,3,4),end="delai_event",start="start",event="event",episode="i",id="id")
test1 <- test1[order(test1$id), ]
 head(test1,10)
     id haplotype cyp3A5 rejet_aigu event delai_event csa1 csa2 csa3 csa4 csa0
1     1       het    NEs          1     0         1.0  153  213  119  236  NaN
254   1       het    NEs          1     0         2.0  153  213  119  236  NaN
507   1       het    NEs          1     0         3.0  153  213  119  236  NaN
760   1       het    NEs          1     0         4.0  153  213  119  236  NaN
1013  1       het    NEs          1     1        10.2  153  213  119  236  NaN
10   10       het    NEs          0     0         1.0  282  101  190  268  NaN
263  10       het    NEs          0     0         2.0  282  101  190  268  NaN
516  10       het    NEs          0     0         3.0  282  101  190  268  NaN
769  10       het    NEs          0     0         4.0  282  101  190  268  NaN
1022 10       het    NEs          0     1         9.3  282  101  190  268  NaN
     start i
1        0 0
254      1 1
507      2 2
760      3 3
1013     4 4
10       0 0
263      1 1
516      2 2
769      3 3
1022     4 4

test1$csa<-ifelse(test1$delai_event<=1,test1$csa1,NA)
> test1$csa<-ifelse(test1$delai_event>1 & test1$delai_event<=2,csa2,test1$csa)
> test1$csa<-ifelse(test1$delai_event>2 & test1$delai_event<=3,csa3,test1$csa)
> test1$csa<-ifelse(test1$delai_event>3 & test1$delai_event<=4,csa4,test1$csa)
> head(test1)
     id haplotype cyp3A5 rejet_aigu event delai_event csa1 csa2 csa3 csa4 csa0
1     1       het    NEs          1     0           1  153  213  119  236  NaN
254   1       het    NEs          1     0           2  153  213  119  236  NaN
507   1       het    NEs          1     0           3  153  213  119  236  NaN
760   1       het    NEs          1     0           4  153  213  119  236  NaN
1013  1       het    NEs          1     1          10  153  213  119  236  NaN
10   10       het    NEs          0     0           1  282  101  190  268  NaN
     start i csa
1        0 0 153
254      1 1 213
507      2 2 119
760      3 3 236
1013     4 4  NA
10       0 0 282


#Version plus moderne : package risksetROC
#Permet de prédire l’influence d’un marqueur à une valeur initiale sur la survie à une ou plusieurs valeur de cutoff (par exemple survie à 1 an).
#Permet de prédire l’évolution de l’AUC ROC d’un marqueur en fonction du temps


library(risksetROC)
 

Evolution de l’AUC ROC au cours du temps
library(MASS)
 data(VA)
head(VA)
  stime status treat age Karn diag.time cell prior
1    72      1     1  69   60         7    1     0
2   411      1     1  64   70         5    1    10
3   228      1     1  38   60         3    1     0
4   126      1     1  63   60         9    1    10
5   118      1     1  65   70        11    1    10
6    10      1     1  49   20         5    1     0
 survival.time=VA$stime
 survival.status=VA$status
 score <- VA$Karn
 cell.type <- factor(VA$cell)
 tx <- as.integer( VA$treat==1 )
 age <- VA$age
 survival.status[survival.time>500 ] <- 0
 survival.time[survival.time>500 ] <- 500
 fit0 <- coxph( Surv(survival.time,survival.status)
 ~ score + cell.type + tx + age, na.action=na.omit )
 eta <- fit0$linear.predictor
 tmax=365
 AUC.CC=risksetAUC(Stime=survival.time,
 status=survival.status, marker=eta, method="Cox", tmax=tmax)
>
 

Arguments
-utimes ordered unique failure times
-St estimated survival probability at utimes
-AUC Area under ROC curve at utimes
-Cindex Cindex (équivalent de l’AUC cf test d’adéquation de Homer Lemeshow)

AUC.CC
$utimes
 [1]   1   2   3   4   7   8  10  11  12  13  15  16  18  19  20  21  22  24  25
[20]  27  29  30  31  33  35  36  42  43  44  45  48  49  51  52  53  54  56  59
[39]  61  63  72  73  80  82  84  87  90  92  95  99 100 103 105 110 111 112 117
[58] 118 122 126 132 133 139 140 143 144 151 153 156 162 164 177 186 200 201 216
[77] 228 231 242 250 260 278 283 287 314 340 357 378 384 389 392 411 467

$St
 [1] 0.98540146 0.97810219 0.97080292 0.96350365 0.94160584 0.91240876
 [7] 0.89781022 0.89051095 0.87591241 0.86131387 0.84671533 0.83941606
[13] 0.81751825 0.80291971 0.78832117 0.77372263 0.76642336 0.75182482
[19] 0.72992701 0.72255401 0.71518101 0.70043501 0.68568901 0.67831601
[25] 0.67094301 0.66357001 0.65619701 0.64882401 0.64145101 0.63407801
[31] 0.62670501 0.61933201 0.59721301 0.57509401 0.56772101 0.55297501
[37] 0.54560201 0.53822901 0.53085601 0.52348301 0.51611001 0.50873701
[43] 0.49399100 0.48661800 0.47913157 0.47164514 0.46403796 0.45643078
[49] 0.44121642 0.42573515 0.41799451 0.41010782 0.40206649 0.39402516
[55] 0.37794250 0.36990117 0.35381851 0.34577718 0.33773585 0.32949839
[61] 0.32126093 0.31302347 0.30478601 0.29654855 0.28831109 0.28007363
[67] 0.27183617 0.26359871 0.25536125 0.23888633 0.23064887 0.22241141
[73] 0.21385713 0.20530284 0.19674856 0.18819427 0.17963999 0.17108570
[79] 0.16208119 0.15307668 0.14407217 0.13506766 0.12606315 0.11705864
[85] 0.10805413 0.09904962 0.09004511 0.08104060 0.07203609 0.06303157
[91] 0.05402706 0.04502255 0.03601804

$AUC
 [1] 0.7256905 0.7285352 0.7303096 0.7267692 0.7349047 0.7287581 0.7243100
 [8] 0.7214425 0.7245912 0.7292719 0.7267385 0.7294186 0.7387009 0.7304743
[15] 0.7309578 0.7278545 0.7148058 0.7235879 0.7230952 0.7115842 0.7160138
[22] 0.7097247 0.7122339 0.7162228 0.7193572 0.7156447 0.7111488 0.7144038
[29] 0.7130880 0.7213468 0.7192513 0.6962411 0.7010544 0.6867048 0.6770297
[36] 0.6750762 0.6785043 0.6882896 0.6771560 0.6822104 0.6723115 0.6819705
[43] 0.6902800 0.6578590 0.6633020 0.6680677 0.6686995 0.6576616 0.6630818
[50] 0.6611074 0.6599110 0.6539309 0.6517310 0.6493720 0.6542648 0.6500445
[57] 0.6603617 0.6516926 0.6562605 0.6430569 0.6540204 0.6490180 0.6507638
[64] 0.6696151 0.6422330 0.6608072 0.6633182 0.6574439 0.6363553 0.6407494
[71] 0.6457570 0.6584999 0.6547602 0.6410482 0.6395669 0.6650322 0.6514258
[78] 0.6562798 0.6755806 0.6649636 0.6571588 0.6760451 0.6602087 0.6937644
[85] 0.6940042 0.6724716 0.6814431 0.6833998 0.7359716 0.6662686 0.7744214
[92] 0.5754732 0.5154262

$Cindex
[1] 0.7032137

#
#Pour avoir la courbe de ROC du marqueur à un temps donné

library(MASS)
 data(VA)
 survival.time=VA$stime
 survival.status=VA$status
 score <- VA$Karn
 cell.type <- factor(VA$cell)
 tx <- as.integer( VA$treat==1 )
 age <- VA$age
 survival.status[survival.time>500 ] <- 0
 survival.time[survival.time>500 ] <- 500
 fit0 <- coxph( Surv(survival.time,survival.status)
+ ~ score + cell.type + tx + age, na.action=na.omit )
 eta <- fit0$linear.predictor
 ROC.CC30=risksetROC(Stime=survival.time, status=survival.status,
+ marker=eta, predict.time=30, method="Cox",
+ main="ROC Curve", lty=2, col="red")
 ROC.CC30
$marker
 [1] -1.524312433 -1.488796336 -1.471446388 -1.443680197 -1.426330248
 [6] -1.402046592 -1.376021669 -1.219898308 -1.176523436 -1.167848462
[11] -1.156616021 -1.132332365 -1.121916123 -1.062932570 -1.028232672
[16] -0.993558953 -0.974441559 -0.939741661 -0.913716738 -0.889459260
[21] -0.837409413 -0.836593215 -0.834851947 -0.827918240 -0.825360774
[26] -0.816685800 -0.793218343 -0.723818547 -0.722077280 -0.670027434
[31] -0.664478737 -0.648424093 -0.639749119 -0.620535053 -0.575553962
[36] -0.566968552 -0.552999375 -0.529621624 -0.520946649 -0.496217031
[41] -0.492274554 -0.487062950 -0.471454269 -0.469375909 -0.466249631
[46] -0.352684943 -0.342145852 -0.338921905 -0.303405809 -0.261513616
[51] -0.253789888 -0.248585250 -0.245931113 -0.217472264 -0.191323800
[56] -0.190507601 -0.173157652 -0.113372571 -0.097640349 -0.078672673
[61] -0.073479542 -0.069874158 -0.064804568 -0.043033036 -0.030920869
[66] -0.030920869 -0.022245895 -0.008333139  0.001008316  0.003779028
[71]  0.017542066  0.021128977  0.021945176  0.127882808  0.185953491
[76]  0.200532727  0.238819536  0.273493256  0.314097415  0.331447364
[81]  0.352384224  0.441788106  0.455667718  0.575136668  0.578723580
[86]  0.603932304  0.644536463  0.716706971  0.748636156  0.809360977
[91]  0.951721301  0.965484338  1.026358878  1.227339790  1.279389636
[96]  1.326351420  2.088532318

$TP
 [1] 1.00000000 0.99778190 0.99548360 0.99314508 0.99074072 0.98829428
 [7] 0.98578771 0.98321504 0.98020767 0.97706699 0.97389894 0.97069510
[13] 0.96741252 0.96409556 0.96057707 0.95693435 0.95316310 0.94931906
[19] 0.94533930 0.94125460 0.93706961 0.93266102 0.92824883 0.92382895
[25] 0.91937832 0.91491629 0.91041539 0.90580761 0.90086869 0.89592117
[31] 0.89070931 0.88546845 0.88014277 0.87477069 0.86929439 0.86356614
[37] 0.85778850 0.85192958 0.84593208 0.83988233 0.83368110 0.82745538
[43] 0.82119712 0.81484042 0.80847049 0.80208062 0.79492227 0.78768808
[49] 0.78043053 0.77291058 0.76506892 0.75716646 0.74922276 0.74125795
[55] 0.73306322 0.72465137 0.71623266 0.70766662 0.69857283 0.68933484
[61] 0.67991996 0.67045606 0.66095797 0.65141161 0.64165514 0.63177977
[67] 0.62190441 0.61194300 0.60184203 0.59164627 0.58142221 0.57105647
[73] 0.56065348 0.55024199 0.53866700 0.52639994 0.51395272 0.50101970
[79] 0.48763038 0.47368621 0.45949799 0.44500959 0.42916620 0.41310138
[85] 0.39499796 0.37682948 0.35819719 0.33879277 0.31793615 0.29640286
[91] 0.27352144 0.24713934 0.22039164 0.19196510 0.15721077 0.12059958
[97] 0.08222806 0.00000000 0.00000000

$FP
 [1] 1.00000000 0.98947368 0.97894737 0.96842105 0.95789474 0.94736842
 [7] 0.93684211 0.92631579 0.91578947 0.90526316 0.89473684 0.88421053
[13] 0.87368421 0.86315789 0.85263158 0.84210526 0.83157895 0.82105263
[19] 0.81052632 0.80000000 0.78947368 0.77894737 0.77894737 0.76842105
[25] 0.75789474 0.74736842 0.73684211 0.72631579 0.71578947 0.70526316
[31] 0.69473684 0.68421053 0.67368421 0.66315789 0.65263158 0.64210526
[37] 0.63157895 0.62105263 0.61052632 0.60000000 0.58947368 0.57894737
[43] 0.56842105 0.55789474 0.54736842 0.53684211 0.52631579 0.51578947
[49] 0.50526316 0.49473684 0.48421053 0.47368421 0.46315789 0.45263158
[55] 0.44210526 0.43157895 0.42105263 0.41052632 0.40000000 0.38947368
[61] 0.37894737 0.36842105 0.35789474 0.34736842 0.33684211 0.32631579
[67] 0.31578947 0.30526316 0.29473684 0.28421053 0.27368421 0.26315789
[73] 0.26315789 0.25263158 0.24210526 0.23157895 0.22105263 0.21052632
[79] 0.20000000 0.18947368 0.17894737 0.16842105 0.15789474 0.14736842
[85] 0.13684211 0.12631579 0.11578947 0.10526316 0.09473684 0.08421053
[91] 0.07368421 0.06315789 0.05263158 0.04210526 0.03157895 0.02105263
[97] 0.01052632 0.00000000 0.00000000

$AUC
[1] 0.7097247


#bootStepAIC bootstrap basé sur l’AIC

library(bootStepAIC)
glmFit1 <- glm(y1 ~ x1 + x2 + x3 + x4 + x5, family = binomial, data = data)
boot.stepAIC(glmFit1, data, B = 50)

object an object representing a model of an appropriate class; currently, "lm", "aov",
"glm", "negbin", "polr", "survreg", and "coxph" objects are supported.
data a data.frame or a matrix that contains the response variable and covariates.
B the number of Bootstrap samples.
alpha the significance level.
direction the direction argument of stepAIC().
k the k argument of stepAIC().
verbose logical; if TRUE information about the evolution of the procedure is printed in the screen.

Basé sur le BIC
boot.stepAIC(glm1, test1, B = 50, k=log(nrow(test1)))


#Formation R jb 6 et 7 décembre 2012

#Chaînes de caractères

#Extraire une partie d’un objet (ex garder que les patients ayant tls dans le nom)
grep(‘ tls’,test)

#Extraire les patients qui contiennent T
test[grep(« T »,rownames(test)),]
#Extraire les patients qui commencent par T
test[grep(« ^T »,rownames(test)),]

#Remplacer tlse par toulouse dans l’id
sub(« tlse », »toulouse »,test$id)
adv$periode<-sub("7j","j7",adv$periode)
 
#Operations ensemblistes
intersect(A,B) ## elements communs à A et B
setdiff(A,B) ## ce qui diffèe entre A et B
is.element(2,A)## est ce que 2 est contenu dans A
id[id==tls38]## à quel position id est = tls38
Diagramme de VENN
A<-1:10
B<-c(3:6,12,15,18)
test<-list(A,B)##on peut aussi faire avec data.frame
library(gplots)
venn(test)

#Date et temps
#Transformer des caractères ou nombres en date ?strptime
#ex date début perf mtx
debut<-"06/12/2012 10:30:00"
 debut<-strptime(debut,"%d/%m/%Y %H:%M:%S")
 debut+30*3600
[1] "2012-12-07 16:30:00 CET"

Sys.time()
[1] "2012-12-09 14:48:31 CET"

##dans combien de temps 31 décembre 2012
> ajourdhui<-Sys.Date()
> as.Date("2012-12-31")-ajourdhui
Time difference of 22 days

#by ou tapply appliquer une fonction à la 1ere colonne par modalité du facteur
tapply(iris[,1],iris[,5],mean)
names(result)##renvoi des éléments que l’on peut sélectionner après
lapply##pour les listes, permet d’avoir des vecteurs de longueur différente
apply#applique une commande à chaque lignes ou colonnes

sapply(seq_len(ncol(a)),function(i) hist(a[,i],main=colnames(a)[i],xlab="x"))

#Graphiques

on crée un matrice avec le nombre de graphes dans la feuille que l’on désire
mat<-matrix(c(2,0,1,3),2,2,byrow=T)##on crée un matrice pour 3 shema avec 2 lignes et 2 col
nf<-layout(mat,c(3,1),c(1 :3),T)##1er vecteur gère largeur et 2eme hauteur ici 3 X/1X
layout.show(nf)
puis les 3 plots à la suite
Pour gérer les marges, titres etc… : par()

#Remplacer une valeur par une autre dans un data.frame
test[3,2]=12
test[test$fac== ‘A’,3]= ‘D’## remplace ds 3eme col ds la variable fac tous les A par des D

#Renommer des colonnes d’un data.frame
colnames(test1)<-c("ID","OUT","TIME")

#une seule colonne
colnames(test1)[3]="TIME"
colnames(mtcars)[13] <-"fueleff"

#une seule ligne
rownames(mtcars)[1] <-"Mazda RX5"

#Renommer une variable dans un data.frame
names(test$
Enlever le X devant nom de variable
sub("^X","",nomcolonne)

sig.pv<-subset(pv,pv<0.05)
names.sig<-sub(".x","",rownames(sig.pv))
 test5<-data.frame(test3$banf.ah,test4[,names.sig])#1
 head(test5)


#Moyenne, min, max, range par sujet
by(Indometh, Indometh$Subject,function(x) min(x$conc,na.rm=T)
by(Indometh, Indometh$Subject,function(x) max(x$conc,na.rm=T)
by(Indometh, Indometh$Subject,function(x) mean(x$conc,na.rm=T)
by(Indometh, Indometh$Subject,function(x) range(x$conc,na.rm=T)

ou
#tapply(Indometh$conc,Indometh$time,median)

#Regression non linéaire et courbe de régression
data(Indometh)
re<-nls(conc~a*exp(-b*time),data=Indometh,start=list(a=3,b=0.16))
re1<-nls(conc~a*exp(-b*time)+c*exp(-d*time),data=Indometh,start=list(a=3,b=0.16,c=0.3,d=0.05))
plot(x=Indometh$time,y=Indometh$conc)
  tt <- seq(0, 8, length = 101)
  lines(tt,col="blue", predict(re1, list(time = tt)))
  lines(tt,col="red", predict(re, list(time = tt)))

conc<-c(seq(from=0,to=40,by=0.5))
sd<-rnorm(81,12,6)
data<-data.frame(conc,sd)
summary(data)
plot(sd~conc,data)
pol1<-nls(sd~a+b*conc,data ,start=list(a=7,b=0.1))
pol2<-nls(sd~a+b*conc+c*conc^2,data ,start=list(a=7,b=0.1,c=0.01))
pol3<-nls(sd~a+b*conc+c*conc^2+d*conc^3,data ,start=list(a=7,b=0.1,c=0.01,d=-0.001))
lines(col="blue", predict(pol1))
 lines(col="red", predict(pol2))
 lines(col="green", predict(pol3))
b1<-BIC(pol1)
b2<-BIC(pol2)
b3<-BIC(pol3)
#graphe avec points et mediane et legend


plot(conc~time, Indometh,main="Indomethacin",xlab="Time (h)", ylab="conc (mg/L)", type="n",xaxt="n",log="y")
subjPlot<-by(Indometh,Indometh$Subject,function(x) lines(conc~time,data=x,type="o",lty=2,new=F))
medIndo<- tapply(Indometh$conc,Indometh$time,median)
lines(x=unique(Indometh$time),y=medIndo,lwd=3,col="black",pch=2, type="o")
legend("topright",lwd=c(1,3),lty=c(2,1),legend=c("individual","Median"))



#Régression logistique polytomique
m<-plr(ah~peptides, data=ah, hess=T)
m<-polr(ah.ord ~ p28054,data=test4,hess=T)
summary(m)
# store table
(ctable <- coef(summary(m)))
# calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
# combined table
(ctable <- cbind(ctable, `p value` = p))
(ci <- confint(glm1)) 
## odds ratios
exp(coef(glm1))
exp(cbind(OR = coef(glm1), ci))
 

#Package lmerTest : calcul des p values et anova lmer

library(lmerTest)
m <- lmer(Informed.liking ~ Gender+Information+Product +(1|Consumer), data=ham)

tests effets fixes
summary(m)
anova(m)
st <- step(m)
plot(st)

test effet aléatoire
rand(m)

#Courbes incidence cumulées
library(cmprsk)
attach(cox1)
print(xx <- cuminc(ftime=delai, fstatus=rejet_1R, group=bin_40))
plot(xx,lty=1,color=c(“blue”,”red”), main=" ", curvlab=c(“mpa<40”,”mpa >40”), ylim=c(0, 1), xlim=c(0,300),
xlab="Years", ylab="Probability", lty=1:length(x))
print(xx)#p value

Seuil ROC en fonciton du temps, ROC time dependent
library(timeROC)
head(cox1)
   id delai debut fin c0_mpa dose_mpa_prise auc_mpa  bin auc_acyl_mpa auc_mpag
1 405    24    18  24  0.523           1500  24.573 haut           NA 1263.475
2 405   406   350 406  1.870           1500  91.295 haut           NA  670.408
3 406    20    19  20  0.300           1500  20.139 haut           NA  755.249
4 406    34    31  34  5.090           1500  44.472 haut           NA 1757.833
5 406    41    36  41  5.090           1500  44.472 haut           NA 1757.833
6 406   396   293 396  1.770           1500  35.240 haut           NA  507.083
  cni auc_csa auc_evero auc_tacro classif_rej rejet_1R rejet_2R anemie diabete
1 tac      NA        NA     0.268          1A        1        0      0       0
2 tac      NA        NA     0.195          1A        1        0      0       0
3 tac      NA        NA     0.168          1B        1        0      0       0
4 tac      NA        NA     0.152          1B        1        0      0       0
5 tac      NA        NA     0.152          R0        0        0      0       0
6 tac      NA        NA     0.135          R0        0        0      0       0

roct<-timeROC(T=cox1$delai,delta=cox1$rejet_1R,marker=-cox1$auc_mpa,cause=1,weighting="cox",times=c(100,200,300),ROC=TRUE)
plotAUCcurve(roct)

res.SeSpPPVNPV.roc <- SeSpPPVNPV(cutpoint=22, T=cox1$delai,delta=cox1$rejet_1R,marker=cox1$auc_mpa, cause=1,weighting="cox", times=c(100,200,300,400))

res.SeSpPPVNPV.roc

Sélectionner que les valeurs >0 dans un tapply

tapply(mdata$out[mdata$out>=0],mdata$id[mdata$out>=0],mean,na.rm=T)
#[ ] transforme la colonne du df en vecteur


#Description détaillée
library(psych)
describe(mdata)

#Présentation sous forme de tableau des résultats/broom
library(broom)

cox1 <- coxph(Surv(debut, fin,event_tox2)~ age +cluster(nom), data=evr)

res3<-tidy(cox1)
cox1 <- coxph(Surv(debut, fin,event_tox2)~ log(conc_evr_res) +cluster(nom), data=evr)
summary(cox1)
res4<-tidy(cox1)

fin<-rbind(res2,res3,res4, res5,res6,res7,res8,res9,res10,res11,res12,res13,res14,res15,res16,res17,res18)

## pour avoir HR et CI95%
fin$hr<-exp(fin$estimate)
fin$ci_bas<-exp(fin$conf.low)
fin$ci_haut<-exp(fin$conf.high)
write.csv2(fin, file="tableau_univ_tox2_marine_110416.csv")

